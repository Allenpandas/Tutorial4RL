# Tutorial4RL
Tutorial4RL: Tutorial for Reinforcement Learning. 强化学习入门教程.

## Related Repository

| Repository                                                   | Remark                                                       |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| [Awesome-Reinforcement-Learning-Papers](https://github.com/Allenpandas/Awesome-Reinforcement-Learning-Papers) | <a href="https://github.com/Allenpandas/Awesome-Reinforcement-Learning-Papers"><img alt="GitHub" src="https://img.shields.io/github/license/Allenpandas/Awesome-Reinforcement-Learning-Papers"></a> <a href="https://github.com/Allenpandas/Awesome-Reinforcement-Learning-Papers"><img alt="GitHub repo size" src="https://img.shields.io/github/repo-size/Allenpandas/Awesome-Reinforcement-Learning-Papers"></a> <a href="https://github.com/Allenpandas/Awesome-Reinforcement-Learning-Papers"><img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/Allenpandas/Awesome-Reinforcement-Learning-Papers"></a> |
| [Tutorial4RL](https://github.com/Allenpandas/Tutorial4RL)    | <a href="https://github.com/Allenpandas/Tutorial4RL"><img alt="GitHub" src="https://img.shields.io/github/license/Allenpandas/Tutorial4RL"></a> <a href="https://github.com/Allenpandas/Tutorial4RL"><img alt="GitHub repo size" src="https://img.shields.io/github/repo-size/Allenpandas/Tutorial4RL"></a> <a href="https://github.com/Allenpandas/Tutorial4RL"><img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/Allenpandas/Tutorial4RL"></a> |
| [2023-Reinforcement-Learning-Conferences-Papers](https://github.com/Allenpandas/2023-Reinforcement-Learning-Conferences-Papers) | <a href="https://github.com/Allenpandas/2023-Reinforcement-Learning-Conferences-Papers"><img alt="GitHub" src="https://img.shields.io/github/license/Allenpandas/2023-Reinforcement-Learning-Conferences-Papers"></a> <a href="https://github.com/Allenpandas/2023-Reinforcement-Learning-Conferences-Papers"><img alt="GitHub repo size" src="https://img.shields.io/github/repo-size/Allenpandas/2023-Reinforcement-Learning-Conferences-Papers"></a> <a href="https://github.com/Allenpandas/2023-Reinforcement-Learning-Conferences-Papers"><img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/Allenpandas/2023-Reinforcement-Learning-Conferences-Papers"></a> |
| [2022-Reinforcement-Learning-Conferences-Papers](https://github.com/Allenpandas/2022-Reinforcement-Learning-Conferences-Papers) | <a href="https://github.com/Allenpandas/2022-Reinforcement-Learning-Conferences-Papers"><img alt="GitHub" src="https://img.shields.io/github/license/Allenpandas/2022-Reinforcement-Learning-Conferences-Papers"></a> <a href="https://github.com/Allenpandas/2022-Reinforcement-Learning-Conferences-Papers"><img alt="GitHub repo size" src="https://img.shields.io/github/repo-size/Allenpandas/2022-Reinforcement-Learning-Conferences-Papers"></a> <a href="https://github.com/Allenpandas/2022-Reinforcement-Learning-Conferences-Papers"><img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/Allenpandas/2022-Reinforcement-Learning-Conferences-Papers"></a> |
| 2021-Reinforcement-Learning-Conferences-Papers               | （Coming Soon）                                              |
| 2020-Reinforcement-Learning-Conferences-Papers               | （Coming Soon）                                              |
| 2019-Reinforcement-Learning-Conferences-Papers               | （Coming Soon）                                              |
| 2018-Reinforcement-Learning-Conferences-Papers               | （Coming Soon）                                              |
| 2017-Reinforcement-Learning-Conferences-Papers               | （Coming Soon）                                              |


**强化学习教程 | RL Tutorials：**

- 《深度强化学习》王树森： [https://www.bilibili.com/video/BV12o4y197US](https://www.bilibili.com/video/BV12o4y197US)
- 《Deep Reinforcement Learning》李宏毅： [https://www.bilibili.com/video/BV1UE411G78S](https://www.bilibili.com/video/BV1UE411G78S)
- 《世界冠军带你从零实践强化学习》百度飞桨团队： [https://www.bilibili.com/video/BV1yv411i7xd](https://www.bilibili.com/video/BV1yv411i7xd)
- 《强化学习白板推导》：[https://space.bilibili.com/97068901/channel/seriesdetail?sid=594040](https://space.bilibili.com/97068901/channel/seriesdetail?sid=594040)
- 《蘑菇书EasyRL》王琦等： [https://github.com/datawhalechina/easy-rl](https://github.com/datawhalechina/easy-rl)
- 《动手学强化学习》张伟楠等： [http://hrl.boyuai.com/](http://hrl.boyuai.com/)



**强化学习开源项目 | RL Open Source Projects：**

- PFRL：基于Pytorch的深度强化学习库： [https://github.com/pfnet/pfrl](https://github.com/pfnet/pfrl)
- 莫烦强化学习TensorFlow代码： [https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow](https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow)
- 百度飞桨PaddlePaddle强化学习代码： [https://github.com/PaddlePaddle/PARL](https://github.com/PaddlePaddle/PARL)
- Github强大的强化学习库： [https://github.com/wwxFromTju/awesome-reinforcement-learning-lib](https://github.com/wwxFromTju/awesome-reinforcement-learning-lib)
- 优达学城（在线教育平台）强化学习库： [https://github.com/udacity/deep-reinforcement-learning](https://github.com/udacity/deep-reinforcement-learning)



**强化学习顶级学术会议：**

- **[AAAI]** AAAI Conference on Artificial Intelligence, AAAI. **（CCF-A会议）**
- **[IJCAI]** International Joint Conference on Artificial Intelligence, IJCAI. **（CCF-A会议）**
- **[ICML]** International Conference on Machine Learning, ICML.**（CCF-A会议）**
- **[NeurIPS]** Annual Conference on Neural Information Processing Systems, NeurIPS. **（CCF-A会议）**
- **[AAMAS]** International Joint Conference on Autonomous Agents and Multi-agent Systems, AAMAS. **（CCF-A会议）**
- **[ICLR]** International Conference on Learning Representations, ICRA. **（CCF-A会议）**
- **[ICRA]** IEEE International Conference on Robotics and Automation, ICRA. **（CCF-A会议）**
- 强化学习顶会文章合集：https://github.com/Allenpandas/Awesome-Reinforcement-Learning-Papers


**强化学习社区 | RL Community：**

- RLChina强化学习社区： [http://rlchina.org/](http://rlchina.org/)
- 智源社区强化学习专栏： [https://hub.baai.ac.cn/?tag_id=74](https://hub.baai.ac.cn/?tag_id=74)
- 智源社区强化学习周刊： [https://hub.baai.ac.cn/users/18447](https://hub.baai.ac.cn/users/18447)





**强化学习学术团队（国内） | RL Academic Team（Home）：**

- 张海峰（中科院自动化所）：https://people.ucas.edu.cn/~zhf （多智能体强化学习、智能体博弈、智能体评估）
- 杨耀东（北大·人工智能研究院）：https://www.yangyaodong.com/ （多智能体强化学习、博弈论）
- 卢宗青（北大·人工智能研究院）：https://z0ngqing.github.io/ （强化学习）
- 张崇洁（清华大学·跨学科信息科学研究所）：http://people.iiis.tsinghua.edu.cn/~zhang/ （深度强化学习、多智能体系统）
- 俞扬（南京大学·人工智能学院）： https://www.yuque.com/eyounx/home （强化学习、离线强化学习）
- 郝建业（天津大学·深度强化学习实验室）： http://www.icdai.org/jianye.html （多智能体强化学习、博弈论）
- 王祥丰（华师大·多智能体人工智能实验室）： https://mail-ecnu.cn/people/xfwang （多智体强化学习）
- 罗军（华为诺亚方舟实验室）：https://openreview.net/profile?id=~Jun_Luo1 （自动驾驶、强化学习）



**强化学习学术团队（国外） | RL Academic Team（Abroad）：**

- Piter Abbeel（加州伯克利·机器人学习实验室）：http://people.eecs.berkeley.edu/~pabbeel/ | http://rll.berkeley.edu/ （强化学习、机器人）
- Jun Wang（伦敦大学·人工智能中心）：http://www0.cs.ucl.ac.uk/staff/jun.wang/ （多智能体强化学习）
- Bo An（新加坡南洋理工大学）：https://personal.ntu.edu.sg/boan/index.html （多智能体系统、博弈论）
- Richard S. Sutton（DeepMind）：http://incompleteideas.net/ 
- David Silver（DeepMind）：https://www.davidsilver.uk/
- Satinder Singh（密歇根大学）：https://web.eecs.umich.edu/~baveja/
- Peter Stone（德克萨斯大学）：https://www.cs.utexas.edu/~pstone/
- Sergey Levine（加州伯克利）：https://people.eecs.berkeley.edu/~svlevine/


